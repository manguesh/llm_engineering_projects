{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "## Scraping a website and generating its summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019974d9-f3ad-4a8a-b5f9-0a3719aea2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "# If this doesn't work, try Kernel menu >> Restart Kernel and Clear Outputs Of All Cells, then run the cells from the top of this notebook down.\n",
    "# If it STILL doesn't work (horrors!) then please see the Troubleshooting notebook in this folder for full instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00743dac-0e70-45b7-879a-d7293a6f68a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The website belongs to Edward Donner, a co-founder and CTO of Nebula.io, where he focuses on applying AI to enhance talent discovery and engagement. He enjoys coding, experimenting with large language models (LLMs), DJing, and electronic music production. The site features various posts and resources related to LLMs and AI, including workshops and guides.\n",
       "\n",
       "Recent announcements include:\n",
       "- January 23, 2025: Resources for a workshop on LLMs and agents.\n",
       "- December 21, 2024: Introduction to a community of SuperDataScientists.\n",
       "- November 13, 2024: Resources for mastering AI and LLM engineering.\n",
       "- October 16, 2024: Resources for transitioning from software engineering to AI data science. \n",
       "\n",
       "Visitors are encouraged to connect with Edward through email and social media."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Create your prompts\n",
    "def scrape_website(url):\n",
    "    # Fetch the webpage\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch the webpage: {response.status_code}\")\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract all text, ignoring HTML and JavaScript\n",
    "    text = soup.get_text(separator='\\n')\n",
    "    \n",
    "    return text\n",
    "\n",
    "def user_prompt_for_website(message):\n",
    "    user_prompt = \"You are looking at the contents of a website with a lot statistics regarding the various LLMs\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows.\\n\\n\"\n",
    "    user_prompt += message\n",
    "    user_prompt += \"\\nprovide a concise summary of the website ignoring the html and javascript and any other navigational content\\n\\n\"\n",
    "    user_prompt += \"\\nIf it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    return user_prompt\n",
    "\n",
    "system_prompt = \"you are the website summary generator\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "\n",
    "def messages_for_website(message):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for_website(message)}\n",
    "    ]\n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "def summarize_website(message):\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for_website(message)\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def display_summary_website(message):\n",
    "    summary = summarize_website(message)\n",
    "    display(Markdown(summary))\n",
    "\n",
    "website_text = scrape_website(\"https://www.vellum.ai/llm-leaderboard\")\n",
    "response = display_summary_website(website_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629eedc-327e-45c6-b7c2-398191a93a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
